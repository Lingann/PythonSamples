# 爬虫介绍

爬虫急救室模拟客户端发送网络请求，接收请求响应，一种按照一定的规则，自动地住区互联网信息的程序

原则上，只要是浏览器(客户端)能做的事情，爬虫都能够做

根据被爬网站的数量的不同，我们把爬虫分为:

* 通用爬虫 ： 通常指搜索引擎的爬虫
* 聚焦爬虫 ： 针对特定网站的爬虫

Robots协议： 网站通过Robot是协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取，但它仅仅是道德层面上的约束

浏览器会主动请求js，css等内容，js会修改页面的内容，js也可以重新发送请求，最后浏览器渲染出来的内容在elements中，其中包含css，图片，js，url地址对应的响应等。

但是在爬虫中，爬虫只会请求url地址，对应的拿到url地址对应的响应。浏览器渲染出来的页面和爬虫请求的页面并不应用，所以在爬虫中，需要以url地址对应的响应为准来进行数据提取

url的形式： 
```
scheme://host[:port#]/path/.../[?query-string][#anchor]
```

* scheme : 协议(例如Lhttp,https,ftp)
* host: 服务器的ip地址或者域名
* port: 服务器的端口（如果走协议默认端口）
* path: 访问资源的路径
* query-string : 参数，发送给http服务器的数据
* anchor: 锚（跳转到网页的指定锚点位置）

- [来源地址](https://juejin.im/entry/5bd7f8326fb9a05d3b33bb28)

## python爬虫
- [python爬虫介绍](https://www.runoob.com/w3cnote/python-spider-intro.html)